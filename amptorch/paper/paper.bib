@article{Lei:2022,
    archivePrefix = {arXiv},
    arxivId = {2102.02390},
    author = {Lei, Xiangyun and Medford, Andrew J.},
    doi = {10.1021/acs.jpclett.2c02100},
    eprint = {2102.02390},
    issn = {19487185},
    journal = {Journal of Physical Chemistry Letters},
    number = {34},
    pages = {7911--7919},
    pmid = {35980312},
    title = {{A Universal Framework for Featurization of Atomistic Systems}},
    volume = {13},
    year = {2022}
}


@article{Hu:2022,
    abstract = {Uncertainty quantification (UQ) is important to machine learning (ML) force fields to assess the level of confidence during prediction, as ML models are not inherently physical and can therefore yield catastrophically incorrect predictions. Established a-posteriori UQ methods, including ensemble methods, the dropout method, the delta method, and various heuristic distance metrics, have limitations such as being computationally challenging for large models due to model re-training. In addition, the uncertainty estimates are often not rigorously calibrated. In this work, we propose combining the distribution-free UQ method, known as conformal prediction (CP), with the distances in the neural network's latent space to estimate the uncertainty of energies predicted by neural network force fields. We evaluate this method (CP+latent) along with other UQ methods on two essential aspects, calibration, and sharpness, and find this method to be both calibrated and sharp under the assumption of independent and identically-distributed (i.i.d.) data. We show that the method is relatively insensitive to hyperparameters selected, and test the limitations of the method when the i.i.d. assumption is violated. Finally, we demonstrate that this method can be readily applied to trained neural network force fields with traditional and graph neural network architectures to obtain estimates of uncertainty with low computational costs on a training dataset of 1 million images to showcase its scalability and portability. Incorporating the CP method with latent distances offers a calibrated, sharp and efficient strategy to estimate the uncertainty of neural network force fields. In addition, the CP approach can also function as a promising strategy for calibrating uncertainty estimated by other approaches.},
    archivePrefix = {arXiv},
    arxivId = {2208.08337},
    author = {Hu, Yuge and Musielewicz, Joseph and Ulissi, Zachary W. and Medford, Andrew J.},
    doi = {10.1088/2632-2153/ACA7B1},
    eprint = {2208.08337},
    issn = {2632-2153},
    journal = {Machine Learning: Science and Technology},
    keywords = {conformal prediction,machine learning force fields,neural network force fields,uncertainty quantification},
    month = {dec},
    number = {4},
    pages = {045028},
    publisher = {IOP Publishing},
    title = {{Robust and scalable uncertainty estimation with conformal prediction for machine-learned interatomic potentials}},
    url = {https://iopscience.iop.org/article/10.1088/2632-2153/aca7b1 https://iopscience.iop.org/article/10.1088/2632-2153/aca7b1/meta},
    volume = {3},
    year = {2022}
}

@article{Khorshidi:2016,
    title = {{Amp: A modular approach to machine learning in atomistic simulations}},
    year = {2016},
    journal = {Computer Physics Communications},
    author = {Khorshidi, Alireza and Peterson, Andrew A.},
    month = {10},
    pages = {310--324},
    volume = {207},
    publisher = {Elsevier B.V.},
    doi = {10.1016/j.cpc.2016.05.010},
    issn = {00104655},
    keywords = {Atomic Simulation Environment (ASE), Density functional theory, Neural networks, Potential energy surface, Zernike polynomials}
}

@article{Lei:2019,
    title = {{ElectroLens: Understanding Atomistic Simulations Through Spatially-resolved Visualization of High-dimensional Features}},
    year = {2019},
    journal = {2019 IEEE Visualization Conference, VIS 2019},
    author = {Lei, Xiangyun and Hohman, Fred and Chau, Duen Horng Polo and Medford, Andrew J.},
    month = {8},
    pages = {196--200},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    url = {https://arxiv.org/abs/1908.08381v3},
    isbn = {9781728149417},
    doi = {10.48550/arxiv.1908.08381},
    arxivId = {1908.08381},
    keywords = {Co-ordinated and Multiple Views, Interaction Design, Molecular Visualization, Visual Design}
}

@article{Musielewicz:2022,
    archivePrefix = {arXiv},
    arxivId = {2205.01223},
    author = {Musielewicz, Joseph and Wang, Xiaoxiao and Tian, Tian and Ulissi, Zachary},
    doi = {10.1088/2632-2153/ac8fe0},
    eprint = {2205.01223},
    issn = {26322153},
    journal = {Machine Learning: Science and Technology},
    keywords = {DFT,active learning,fine tuning,graph potential energy surface},
    number = {3},
    title = {{FINETUNA: fine-tuning accelerated molecular simulations}},
    volume = {3},
    year = {2022}
}

@article{Liu:2020,
    title = {{SingleNN: Modified Behler-Parrinello Neural Network with Shared Weights for Atomistic Simulations with Transferability}},
    year = {2020},
    journal = {Journal of Physical Chemistry C},
    author = {Liu, Mingjie and Kitchin, John R.},
    number = {32},
    month = {8},
    pages = {17811--17818},
    volume = {124},
    publisher = {American Chemical Society},
    doi = {10.1021/acs.jpcc.0c04225},
    issn = {19327455}
}

@misc{Tietz:2017,
    title = {{skorch: A scikit-learn compatible neural network library that wraps PyTorch}},
    year = {2017},
    author = {Tietz, Marian and Fan, Thomas J. and Nouri, Daniel and Bossan, Benjamin},
    month = {7}
}

@misc{Chu:2010,
    title = {{Lightning Memory-Mapped Database Manager (LMDB)}},
    year = {2010},
    author = {Chu, Howard and Hedenfalk, Martin},
}


@article{Behler:2015,
    author = {Behler, J{\"{o}}rg},
    doi = {10.1002/qua.24890},
    issn = {1097461X},
    journal = {International Journal of Quantum Chemistry},
    keywords = {molecular dynamics,neural network potentials},
    number = {16},
    pages = {1032--1050},
    title = {{Constructing high-dimensional neural network potentials: A tutorial review}},
    volume = {115},
    year = {2015}
}


@article{Larsen:2017,
    title = {{The atomic simulation environment—a Python library for working with atoms}},
    year = {2017},
    journal = {Journal of Physics: Condensed Matter},
    author = {Hjorth Larsen, Ask and J{\O}rgen Mortensen, Jens and Blomqvist, Jakob and Castelli, Ivano E. and Christensen, Rune and Du{\l}ak, Marcin and Friis, Jesper and Groves, Michael N. and Hammer, BjØrk and Hargus, Cory and Hermes, Eric D. and Jennings, Paul C. and Bjerre Jensen, Peter and Kermode, James and Kitchin, John R. and Leonhard Kolsbjerg, Esben and Kubal, Joseph and Kaasbjerg, Kristen and Lysgaard, Steen and Bergmann Maronsson, Jón and Maxson, Tristan and Olsen, Thomas and Pastewka, Lars and Peterson, Andrew and Rostgaard, Carsten and Schi{\O}tz, Jakob and Sch{\"{u}}tt, Ole and Strange, Mikkel and Thygesen, Kristian S. and Vegge, Tejs and Vilhelmsen, Lasse and Walter, Michael and Zeng, Zhenhua and Jacobsen, Karsten W.},
    number = {27},
    month = {6},
    pages = {273002},
    volume = {29},
    publisher = {IOP Publishing},
    url = {https://iopscience.iop.org/article/10.1088/1361-648X/aa680e https://iopscience.iop.org/article/10.1088/1361-648X/aa680e/meta},
    doi = {10.1088/1361-648X/AA680E},
    issn = {0953-8984},
    pmid = {28323250},
    keywords = {density functional theory, electronic structure theory, molecular dynamics}
}

@article{Chanussot:2021,
    archivePrefix = {arXiv},
    arxivId = {2010.09990},
    author = {Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth and Lavril, Thibaut and Shuaibi, Muhammed and Riviere, Morgane and Tran, Kevin and Heras-Domingo, Javier and Ho, Caleb and Hu, Weihua and Palizhati, Aini and Sriram, Anuroop and Wood, Brandon and Yoon, Junwoong and Parikh, Devi and Zitnick, C. Lawrence and Ulissi, Zachary},
    doi = {10.1021/acscatal.0c04525},
    eprint = {2010.09990},
    issn = {21555435},
    journal = {ACS Catalysis},
    keywords = {catalysis,datasets,force field,graph convolutions,machine learning,renewable energy},
    number = {10},
    pages = {6059--6072},
    title = {{Open Catalyst 2020 (OC20) Dataset and Community Challenges}},
    volume = {11},
    year = {2021}
}
