{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a notebook to evaluate trained  TRPO agent in SurfRecon environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: MKL_DEBUG_CPU_TYPE=5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env MKL_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env MKL_DEBUG_CPU_TYPE=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 12:26:58.111548: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 12:26:58.324341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:26:58.339450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:26:58.339507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:26:58.853252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:26:58.853332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:26:58.853338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-26 12:26:58.853357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:26:58.853388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13541 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "seed = 30\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# 强制加入正确的路径\n",
    "sys.path.insert(0, '/root/apps/surfrecon')\n",
    "\n",
    "import gym\n",
    "from surface_seg.envs.surfrecon_env import MCSEnv\n",
    "from surface_seg.utils.callback_new import Callback\n",
    "from tensorforce.execution import Runner\n",
    "import gym.wrappers\n",
    "import numpy as np\n",
    "import tensorforce\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 500\n",
    "thermal_threshold = 3\n",
    "num_parallel = 32\n",
    "# Substitute your own path to save file during evaluation\n",
    "save_dir = './result_multi_env/experiments/test_surfrecon_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial energy 2.4803847437851605\n",
      "thermal energy 0.413616\n",
      "3KT 1.240848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/catgym_AgPd/lib/python3.7/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "def setup_env(recording=True, structure=None, structure_idx=None):\n",
    "    \n",
    "    # Set up gym\n",
    "    MCS_gym = MCSEnv(observation_fingerprints=True, \n",
    "                     observation_forces=True,\n",
    "                     permute_seed=42, \n",
    "                     save_dir = save_dir,\n",
    "                     timesteps = timesteps,\n",
    "                     thermal_threshold = thermal_threshold,\n",
    "                     save_every_min = 1,\n",
    "                     save_every = 50,\n",
    "                     step_size = 0.1,                    \n",
    "                    )\n",
    "    \n",
    "    if recording:\n",
    "    # Wrap the gym to provide video rendering every 50 steps\n",
    "        MCS_gym = gym.wrappers.Monitor(MCS_gym, \n",
    "                                         os.path.join(save_dir, 'vid'), \n",
    "                                         force=True,\n",
    "                                        video_callable = lambda episode_id: (episode_id+1)%50==0) #every 50, starting at 51\n",
    "    \n",
    "    #Convert gym to tensorforce environment\n",
    "    env = tensorforce.environments.OpenAIGym(MCS_gym,\n",
    "                                         max_episode_timesteps=timesteps,\n",
    "                                         visualize=False)\n",
    "    \n",
    "    return env\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create a environment for checking the intial energy and thermal energy\n",
    "\"\"\"\n",
    "env = setup_env().environment.env\n",
    "print('initial energy', env.initial_energy)\n",
    "print('thermal energy', env.thermal_energy)\n",
    "n =thermal_threshold\n",
    "print('%dKT' %n, n * env.thermal_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and agent in tensorforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 12:27:00.445667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:00.445762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:00.445775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/catgym_AgPd/lib/python3.7/site-packages/tensorforce/core/module.py:701: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/catgym_AgPd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: calling foldl_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldl(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldl(fn, elems))\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 12:27:03.844241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:03.844425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:03.844552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:03.845286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:03.845314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-26 12:27:03.845382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 12:27:03.845400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13541 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Restoring parameters from ../../surface_seg/pretrained/saved_agent/agent\n"
     ]
    }
   ],
   "source": [
    "from tensorforce.agents import Agent\n",
    "# Substitute your own path to saved trained agent\n",
    "saved_agent_dir = os.path.join('../../surface_seg/pretrained/', 'saved_agent')\n",
    "agent = Agent.load(saved_agent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('agent', 'ppo'), ('states', {'TS': {'type': 'float', 'shape': [1]}, 'energy': {'type': 'float', 'shape': [1]}, 'fingerprints': {'type': 'float', 'shape': [112]}, 'forces': {'type': 'float', 'shape': [24]}, 'positions': {'type': 'float', 'shape': [24]}}), ('actions', {'action_type': {'type': 'int', 'shape': [], 'num_values': 4}, 'atom_selection': {'type': 'int', 'shape': [], 'num_values': 8}, 'movement': {'type': 'float', 'shape': [1, 3], 'min_value': -0.10000000149011612, 'max_value': 0.10000000149011612}}), ('max_episode_timesteps', 500), ('batch_size', 1), ('network', 'auto'), ('use_beta_distribution', True), ('memory', 50000), ('update_frequency', None), ('learning_rate', 0.001), ('subsampling_fraction', 0.33), ('optimization_steps', 10), ('likelihood_ratio_clipping', 0.2), ('discount', 0.99), ('estimate_terminal', False), ('critic_network', None), ('critic_optimizer', None), ('preprocessing', None), ('exploration', {'type': 'decaying', 'unit': 'timesteps', 'decay': 'exponential', 'initial_value': 0.2, 'decay_steps': 50000, 'decay_rate': 0.5}), ('variable_noise', 0.0), ('l2_regularization', 0.0), ('entropy_regularization', 0.0), ('name', 'agent'), ('device', None), ('parallel_interactions', 32), ('seed', None), ('execution', None), ('saver', None), ('summarizer', None), ('recorder', None), ('config', None)])\n"
     ]
    }
   ],
   "source": [
    "# Check agent specifications\n",
    "print(agent.spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the trained DRL agent in parallel (multiple environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|                    | 0/1000 [00:00, reward=0.00, ts/ep=0, sec/ep=0.00, ms/ts=0.0, agent=0.0%, comm=0.0%]2024-11-26 12:27:07.609131: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Episodes: 100%|████████| 1000/1000 [1:38:07, reward=0.00, ts/ep=500, sec/ep=186.12, ms/ts=372.2, agent=3.0%, comm=91.0%]\n"
     ]
    }
   ],
   "source": [
    "num_episode = 1000\n",
    "\n",
    "callback = Callback(num_episode, save_dir).episode_finish\n",
    "\n",
    "runner = Runner( \n",
    "    agent=agent,\n",
    "    environments=[setup_env(recording=False) for _ in range(num_parallel)],\n",
    "    max_episode_timesteps=timesteps,\n",
    "    remote='multiprocessing',\n",
    ")\n",
    "\n",
    "runner.run(num_episodes=num_episode, callback=callback, callback_episode_frequency=1)\n",
    "runner.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surfrecon",
   "language": "python",
   "name": "surfrecon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
